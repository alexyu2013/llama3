{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "7517625b-d21b-4155-9ba0-a0b3bc782714",
   "metadata": {},
   "outputs": [],
   "source": [
    "import ollama\n",
    "from sqlalchemy import create_engine, text\n",
    "import whisper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "74a0423e-c435-4733-b084-1c9de4313f6e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Ravenclaw', 100)\n",
      "('Slytherin', 120)\n",
      "('Hufflepuff', 100)\n",
      "('Gryffindor', 85)\n"
     ]
    }
   ],
   "source": [
    "# Test the connection by fetching the PostgreSQL version\n",
    "engine = create_engine('postgresql://postgres:password@localhost/postgres')\n",
    "try:\n",
    "    with engine.connect() as connection:\n",
    "        result = connection.execute(text(\"SELECT * FROM house_points\"))\n",
    "        for row in result:\n",
    "            print(row)\n",
    "except Exception as e:\n",
    "    print(f\"Connection failed: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3be2ba1-d1fd-48b9-8f11-b697efb1040f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def audio_to_text(audio_file):\n",
    "    model = whisper.load_model(\"turbo\")\n",
    "    result = model.transcribe(audio_file)\n",
    "    return result['text']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8c33e22d-b5ae-4e2b-9762-57e8c3bf6e24",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to convert text to SQL using Ollama (text-to-SQL model)\n",
    "import json\n",
    "\n",
    "def text_to_sql(natural_language_text):\n",
    "    # Create a prompt that gives context about the DB schema\n",
    "    # Ask for only the SQL query in the response\n",
    "    table_schemas = \"\"\"\n",
    "    house_points(house_name TEXT PRIMARY KEY, points INTEGER)\n",
    "    \"\"\"\n",
    "    \n",
    "    prompt = f\"\"\"\n",
    "    You are a SQL expert.\n",
    "    \n",
    "    Please help to convert the following natural language command into a valid UPDATE SQL query. Your response should ONLY be based on the given context and follow the response guidelines and format instructions.\n",
    "\n",
    "    ===Tables\n",
    "    {table_schemas}\n",
    "\n",
    "    ===Response Guidelines\n",
    "    1. If the provided context is sufficient, please generate a valid query WITHOUT any explanations for the question.\n",
    "    2. Please format the query before responding.\n",
    "    3. Please always respond with a valid well-formed JSON object with the following format\n",
    "    4. There are only UPDATE queries and points are either added or deducted from a house\n",
    "\n",
    "    ===Response Format\n",
    "    {{\n",
    "        \"query\": \"A valid UPDATE SQL query when context is sufficient.\",\n",
    "    }}\n",
    "\n",
    "    ===command\n",
    "    {natural_language_text}\n",
    "    \"\"\"\n",
    "    \n",
    "    # Request SQL conversion from Ollama\n",
    "    response = ollama.chat(\n",
    "            model=\"llama3\",\n",
    "            messages=[{\"role\": \"user\", \"content\": prompt}]\n",
    "        )\n",
    "    # Directly return the content as it should now be only the SQL query\n",
    "    # Parse the JSON response and return the SQL query if provided\n",
    "    response_content = response['message']['content']\n",
    "    \n",
    "    try:\n",
    "        response_json = json.loads(response_content)\n",
    "        if \"query\" in response_json:\n",
    "            return response_json[\"query\"]\n",
    "        else:\n",
    "            return f\"Error: {response_json.get('explanation', 'No explanation provided.')}\"\n",
    "    except json.JSONDecodeError:\n",
    "        return \"Error: Failed to parse response as JSON.\"\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "a748015a-a7dc-4fba-81c9-98199db3975c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to run SQL queries using SQLAlchemy\n",
    "def run_sql_query(query):\n",
    "    # Define connection string to your database (for example, SQLite)\n",
    "    engine = create_engine('postgresql://postgres:password@localhost/postgres')\n",
    "    try:\n",
    "        with engine.connect() as conn:\n",
    "            # Execute the SQL query\n",
    "            result = conn.execute(text(query))\n",
    "            conn.commit()\n",
    "            \n",
    "            # If it's a SELECT query, fetch and print the results\n",
    "            if query.strip().lower().startswith(\"select\"):\n",
    "                for row in result:\n",
    "                    print(row)\n",
    "            else:\n",
    "                print(\"Query executed successfully.\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error executing query: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "88f0585d-8001-4b1d-91f5-e316f47c1cab",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.12/site-packages/whisper/__init__.py:150: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  checkpoint = torch.load(fp, map_location=device)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/whisper/transcribe.py:126: UserWarning: FP16 is not supported on CPU; using FP32 instead\n",
      "  warnings.warn(\"FP16 is not supported on CPU; using FP32 instead\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Transcribed Text:  Five points from Gryffindor.\n"
     ]
    }
   ],
   "source": [
    "audio_file = \"snape.wav\"  # Path to the audio file\n",
    "transcript = audio_to_text(audio_file)\n",
    "print(\"Transcribed Text:\", transcript)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "c54c5fa9-d72d-41dd-8b3f-f63db78c1510",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' Five points from Gryffindor.'"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "transcript"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d9dc8d44-ce5d-42bb-b0b1-a9d78bc3082b",
   "metadata": {},
   "outputs": [],
   "source": [
    "sql_query = text_to_sql(transcript)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d45f8518-5846-454c-b7bf-8b73e99921b0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"UPDATE house_points SET points = points - 5 WHERE house_name = 'Gryffindor';\""
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sql_query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "528a8cb5-31ca-4b71-ab6c-0b74ba5aecb2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query executed successfully.\n"
     ]
    }
   ],
   "source": [
    "run_sql_query(sql_query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "c304ddde-6db1-4691-8cf8-7937ea53424d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Ravenclaw', 100)\n",
      "('Slytherin', 120)\n",
      "('Hufflepuff', 100)\n",
      "('Gryffindor', 95)\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    with engine.connect() as connection:\n",
    "        result = connection.execute(text(\"SELECT * FROM house_points\"))\n",
    "        for row in result:\n",
    "            print(row)\n",
    "except Exception as e:\n",
    "    print(f\"Connection failed: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "19969f71-9ddb-4943-b16d-a945718dd0f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recording...\n",
      "Recording finished.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.12/site-packages/whisper/__init__.py:150: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  checkpoint = torch.load(fp, map_location=device)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/whisper/transcribe.py:126: UserWarning: FP16 is not supported on CPU; using FP32 instead\n",
      "  warnings.warn(\"FP16 is not supported on CPU; using FP32 instead\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Transcription:  10 points to Gryffindor\n"
     ]
    }
   ],
   "source": [
    "import whisper\n",
    "import sounddevice as sd\n",
    "import numpy as np\n",
    "import tempfile\n",
    "import os\n",
    "import wave\n",
    "\n",
    "# Function to record audio from the microphone and save it as a WAV file\n",
    "def record_audio(duration, sample_rate=16000):\n",
    "    print(\"Recording...\")\n",
    "    audio_data = sd.rec(int(duration * sample_rate), samplerate=sample_rate, channels=1, dtype='float32')\n",
    "    sd.wait()  # Wait for the recording to finish\n",
    "    print(\"Recording finished.\")\n",
    "    \n",
    "    # Save the audio to a temporary WAV file\n",
    "    temp_wav = tempfile.NamedTemporaryFile(delete=False, suffix=\".wav\")\n",
    "    with wave.open(temp_wav.name, 'wb') as wf:\n",
    "        wf.setnchannels(1)  # Mono channel\n",
    "        wf.setsampwidth(2)   # 16-bit audio\n",
    "        wf.setframerate(sample_rate)\n",
    "        wf.writeframes(np.int16(audio_data * 32767))  # Convert float32 to int16\n",
    "    \n",
    "    return temp_wav.name\n",
    "\n",
    "# Function to transcribe audio from the microphone using Whisper\n",
    "def audio_to_text_from_mic(duration=5):\n",
    "    # Record audio from the microphone\n",
    "    audio_file = record_audio(duration)\n",
    "\n",
    "    # Load Whisper model\n",
    "    model = whisper.load_model(\"turbo\")  # You can use \"turbo\", \"small\", etc.\n",
    "    \n",
    "    # Transcribe the recorded audio file\n",
    "    result = model.transcribe(audio_file)\n",
    "\n",
    "    # Delete the temporary audio file after transcription\n",
    "    os.remove(audio_file)\n",
    "\n",
    "    return result['text']\n",
    "\n",
    "# Example usage\n",
    "text = audio_to_text_from_mic(duration=3)  # Record for 5 seconds\n",
    "print(\"Transcription:\", text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "6bb04831-29e7-47d7-be5d-08382021cc7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "sql_query = text_to_sql(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "aa8d7fde-3d80-4ac0-bc12-10606a5b2f47",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"UPDATE house_points SET points = points + 10 WHERE house_name = 'Gryffindor';\""
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sql_query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "eef7a50b-42ee-4e9a-ae0d-2dfa76d20f18",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query executed successfully.\n"
     ]
    }
   ],
   "source": [
    "run_sql_query(sql_query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "d9a81a87-72ea-4bf2-b921-76423dd221d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Ravenclaw', 100)\n",
      "('Slytherin', 120)\n",
      "('Hufflepuff', 100)\n",
      "('Gryffindor', 105)\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    with engine.connect() as connection:\n",
    "        result = connection.execute(text(\"SELECT * FROM house_points\"))\n",
    "        for row in result:\n",
    "            print(row)\n",
    "except Exception as e:\n",
    "    print(f\"Connection failed: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "639446c1-5b0b-486d-88f8-fb5804f2722c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
