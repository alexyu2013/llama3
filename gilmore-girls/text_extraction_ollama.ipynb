{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "b62391d7-a2f3-4ef0-8750-da4c7bcd760d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import ollama"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "a2d76887-a358-44c3-a6a1-5393f5813cb3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ep-1.xml\n",
      "ep-2.xml\n",
      "ep-3.xml\n",
      "ep-4.xml\n",
      "ep-5.xml\n",
      "ep-6.xml\n",
      "ep-7.xml\n",
      "ep-8.xml\n",
      "ep-9.xml\n",
      "ep-10.xml\n"
     ]
    }
   ],
   "source": [
    "# Loop through each XML file\n",
    "extracted_text = []\n",
    "for file_number in range(1, 11):\n",
    "    file_name = f\"ep-{file_number}.xml\"  # Replace with your actual file name\n",
    "    with open(file_name, 'r', encoding='utf-8') as f:\n",
    "        print(file_name)\n",
    "        file_content = f.read()\n",
    "        soup = BeautifulSoup(file_content, 'xml')\n",
    "        \n",
    "        # Find all <p> elements and extract text\n",
    "        p_elements = soup.find_all('p')\n",
    "        for p in p_elements:\n",
    "            text = p.get_text(strip=True)  # Get text without spaces\n",
    "            extracted_text.append(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "741fd5b8-a86a-4bb9-b4d9-52a77ccee549",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Here is the output:\n",
      "\n",
      "Huckleberry Finn : Mark Twain\n",
      "Moby Dick : Herman Melville\n",
      "Madame Bovary : Gustave Flaubert\n",
      "The Little Match Girl : Hans Christian Andersen\n",
      "Wuthering Heights : Emily BrontÃ«\n",
      "Peyton Place : Richard Peabody Simmons\n",
      "Gaucho : Jorge Luis Borges\n",
      "TO PERM OR NOT TO PERM : William Shakespeare (as Hamlet)\n",
      "The Counter of Saint Petersburg : Alexander Pushkin\n",
      "VALLEY OF THE DOLLS : Jacqueline Susann\n",
      "All the King's Men : Robert Penn Warren\n",
      "Mushrooms : Lewis Carroll\n",
      "9 1/2 Weeks : Judith Viola\n",
      "Willy Wonka : Roald Dahl\n",
      "The Way We Were : Arthur Laurents\n",
      "Beloved : Toni Morrison\n",
      "Pride and Prejudice : Jane Austen\n",
      "The Portable Dorothy Parker : Dorothy Parker\n",
      "Alice in Wonderland : Lewis Carroll\n",
      "The Gift of the Magi : O. Henry\n",
      "Metamorphosis : Kafka\n",
      "A Christmas Carol : Charles Dickens\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "\n",
    "chunk_size = 100\n",
    "iterations = 3  # Number of iterations\n",
    "text_chunks = [extracted_text[i:i+chunk_size] for i in range(0, len(extracted_text), chunk_size)]\n",
    "\n",
    "for iteration in range(iterations):\n",
    "    print(f\"Iteration {iteration + 1}/{iterations}\")\n",
    "    \n",
    "    all_responses = []\n",
    "    \n",
    "    for idx, chunk in enumerate(text_chunks, start=1):\n",
    "        combined_text = \" \".join(chunk)\n",
    "        \n",
    "        prompt = f\"\"\"\n",
    "        - Below is a subtitle file from a TV episode. Your task is to identify and extract any mentions of famous books and their corresponding authors from the text.\n",
    "        - Do not include random text or phrases that are not actual book titles.\n",
    "        - If you cannot find any book mentions, output 'NA'.\n",
    "        - Ensure that each book title is accurately matched with its author.\n",
    "        - Output the list in the format: '<Name of the book> : <Name of the author>'.\n",
    "        - Separate each book entry with a newline.\n",
    "        - Dont supplement with any additional notes at the start or the finish of the output text. \n",
    "        \n",
    "        Conversation:\n",
    "        {combined_text}\n",
    "        \"\"\"\n",
    "        \n",
    "        # Call the LLaMA 3 model\n",
    "        response = ollama.chat(\n",
    "            model=\"llama3\",\n",
    "            messages=[{\"role\": \"user\", \"content\": prompt}]\n",
    "        )\n",
    "        \n",
    "        # Extract the response content\n",
    "        response_text = response['message']['content'].strip()\n",
    "        print(f\"Chunk {idx}/{len(text_chunks)} Output:\\n{response_text}\\n\")\n",
    "        all_responses.append(response_text)\n",
    "        \n",
    "        time.sleep(10)  # Adjust as needed\n",
    "\n",
    "    # For the next iteration, use the cleaned output from this iteration as input\n",
    "    cleaned_input = \"\\n\".join([r for r in all_responses if r != 'NA'])  # Filter out 'NA' entries\n",
    "    text_chunks = [cleaned_input[i:i+chunk_size] for i in range(0, len(cleaned_input), chunk_size)]  # Re-chunk the output for the next iteration\n",
    "\n",
    "# Final cleaned output\n",
    "final_output = \"\\n\".join(all_responses)\n",
    "print(\"Final Cleaned Output:\")\n",
    "print(final_output)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e49b58b1-75ec-4288-9f03-67efb0516ee2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
